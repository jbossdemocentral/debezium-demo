// versions
:debezium: 1.1
:streams: 1.5
:camel-kafka-connectors: 0.4.0

// URLs
//:fuse-documentation-url: https://access.redhat.com/documentation/en-us/red_hat_fuse/{fuse-version}/
:openshift-console-url: {openshift-host}/topology/ns/debezium-basic-demo/graph

// attributes
:title: Introducing Debezium
:standard-fail-text: Verify that you followed all the steps. If you continue to have issues, contact your administrator.

// id syntax is used here for the custom IDs
[id='debezium-basic-demo']
= {title}

// Description text for the Solution Pattern.
This tutorial demonstrates how to use Debezium to capture updates from a MySQL database. As the data in the database changes, you can see the resulting event in AMQ streams.

// Additional introduction content..
Debezium is a set of distributed services, built on top of Apache Kafka, that captures changes that occur in database tables, and sends them to Kafka.
When a change occurs in your database, as when a record is created, deleted, or updated, Debezium consumes the change event and sends a record of it to a Kafka topic. 
Applications, in turn, can subscribe to the Kafka topic, and read the event records, in the order in which they were generated.
Because applications can consume event records as they become available, they can respond quickly to changes.

Further, because Kafka topic storage retains the history of the event records that a database table emits, applications have access to the full history of data changes in the source database. 
Even if the application stops unexpectedly, it does not miss changes that occur during the outage. 
When the application restarts, it reconnects to Kafka, and resumes consuming the events from the point in the topic where it left off.


image::images/debezium-basic.png[Debezium, role="integr8ly-img-responsive"]

Debezium provides a set of connectors for ingesting changes from different database management systems, including MySQL, postgreSQL, MongoDB, SQL Server, and Db2. 
In this tutorial, we'll use the MySQL connector. 

For this tutorial we'll work in the OpenShift `debezium-basic-demo` project. 
In this project, the following resources are deployed:

- An example MySQL database.
- A single node Kafka cluster.
- A Kafka Connect cluster with the MySQL connector.

image::images/debezium-basic-topology.png[Debezium, role="integr8ly-img-responsive"]

[type=walkthroughResource,serviceName=openshift]
.Red Hat OpenShift
****
* link:{openshift-console-url}[Console, window="_blank"]
****
// <-- END OF SOLUTION PATTERN GENERAL INFO -->

// <-- START OF SOLUTION PATTERN TASKS -->
[time=5]
[id='starting-mysql-client']
== Starting a MySQL command line client

We can access the sample MySQL `inventory` database by opening a terminal window in the tooling pod, and starting a MySQL command line client.
 
=== Accessing the tooling terminal

. From a new browser tab, open the link:{openshift-console-url}[*Topology*, window="_blank"] view of the OpenShift console.
. Verify that you are using the `debezium-basic-demo` project.
. From the navigation panel, switch from the *Administrator* view to the *Developer* view.
. In the topology diagram, click the *tooling* application to view its details, and then click the pod name.
+
image::images/tooling-topology.png[Tooling, role="integr8ly-img-responsive"]

. From *Pod Details*, click the *Terminal* tab to open a working terminal window.
+
image::images/tooling-terminal.png[Tooling terminal, role="integr8ly-img-responsive"]


=== Exploring the database

. From the shell prompt in the terminal window, enter the following command to start the MySQL command line client in the container, and log into the sample `inventory` database.
+
[source,bash,subs="attributes+"]
----
mycli -h mysql -u mysqluser -p mysqlpw inventory
----
+
The command returns information about the MySQL CLI, similar to the following output:
+
----
mysql 5.7.30-log
mycli 1.20.1
Chat: https://gitter.im/dbcli/mycli
Mail: https://groups.google.com/forum/#!forum/mycli-users
Home: http://mycli.net
Thanks to the contributor - Ryan Smith
----

. At the `mysql mysqluser@mysql:inventory>` command prompt, enter the following command to list the tables in the database:
+
[source,sql,subs="attributes+"]
----
SHOW TABLES;
----
+
The command returns the following output:
+
----
+---------------------+
| Tables_in_inventory |
+---------------------+
| addresses           |
| customers           |
| geom                |
| orders              |
| products            |
| products_on_hand    |
+---------------------+
6 rows in set
Time: 0.012s
----

. Submit other SQL queries to further explore the database and view the data that it contains. 
For example, to list all of the entries in the `customers` table, submit the following query:
+
[source,sql,subs="attributes+"]
----
SELECT * FROM customers;
----
+
The query returns the following table:
+
----
+------+------------+-----------+-----------------------+
| id   | first_name | last_name | email                 |
+------+------------+-----------+-----------------------+
| 1001 | Sally      | Thomas    | sally.thomas@acme.com |
| 1002 | George     | Bailey    | gbailey@foobar.com    |
| 1003 | Edward     | Walker    | ed@walker.com         |
| 1004 | Anne       | Kretchmar | annek@noanswer.org    |
+------+------------+-----------+-----------------------+

4 rows in set
Time: 0.011s
----
+
After you're done exploring the database, leave the MySQL CLI running in the terminal on this tab, so that we can come back to it later.

[type=verification]
====
Did it work?
====

[type=verificationFail]
{standard-fail-text}
// <-- END OF SOLUTION PATTERN TASKS -->

// <-- START OF SOLUTION PATTERN TASKS -->
[time=5]
[id='view-change-events']
== Viewing change events

After the Debezium MySQL connector deploys, it starts to capture data change events from  the `inventory` database. Events are written to topics with names prefixed by `dbserver-mysql`.

In this tutorial, we will examine the topic `dbserver-mysql.inventory.customers`. 
In this topic, we'll view several types of change events and see how the MySQL connector captures them.
We'll complete the following tasks:

- View a create event.
- Update the database and view the resulting update event.
- Delete a record in the database and view the resulting delete event.
- Restart Kafka Connect and change the database.

=== Viewing a CREATE event

Now let's examine a Kafka topic. To do this we'll use the `kafkacat` utility.  
By viewing the `dbserver-mysql.inventory.customers` topic, we'll see how the MySQL connector captures CREATE events in the `inventory` database. 
In this topic, CREATE events capture operations that add new customers to the database.

. From the *Resources* box, click *Console* to open a second OpenShift console in another tab, then navigate to the tooling pod to open a terminal window.
.. Open the link:{openshift-console-url}[*Topology*, window="_blank"] view of the OpenShift console.
.. From the topology diagram, click the *tooling* pod to open the details panel, and then click the pod name.
.. From the shell prompt, enter the following command to start the `kafkacat` utility and configure it to watch the `dbserver-mysql.inventory.customers` topic from the beginning of the topic.
+
[source,bash,subs="attributes+"]
----
kafkacat -b demo-kafka-bootstrap:9092 -t dbserver-mysql.inventory.customers  | jq .
----
+
The `kafkacat` utility returns the event records from the `customers` table. 
There are four events, one for each row in the table. 
Each event is formatted in JSON, the default format for Kafka Connect to represent the data. 
There are two JSON documents for each event: one for the key, and one for the value.
+
The command returns JSON that is similar to the following output:
+
----
{
  "schema": {
    "type": "struct",
    "fields": [
      {
        "type": "struct",
        "fields": [
...
        ]
      }
      ]
    },
    "op": "c",
    "ts_ms": 1594158476924,
    "transaction": null
  }
}
----
+
[NOTE]
====
For as long as `kafkacat` is running, it watches the topic continuously. New events appear automatically as they occur.
====

. Review the details returned for the value document of the event.
+
The event’s _value_ shows that the row was created, and it lists the fields that the row contains. 
In this case, the event contains the `id`, `first_name`, `last_name`, and `email` for the specified row.
+
The following details are included in the _value_ document for the last event (formatted for readability):
+
[source,json]
----
{
  "schema": {
    "type": "struct",
    "fields": [
      {
        "type": "struct",
        "fields": [
          {
            "type": "int32",
            "optional": false,
            "field": "id"
          },
          {
            "type": "string",
            "optional": false,
            "field": "first_name"
          },
          {
            "type": "string",
            "optional": false,
            "field": "last_name"
          },
          {
            "type": "string",
            "optional": false,
            "field": "email"
          }
        ],
        "optional": true,
        "name": "dbserver_mysql.inventory.customers.Value",
        "field": "before"
      },
      {
        "type": "struct",
        "fields": [
          {
            "type": "int32",
            "optional": false,
            "field": "id"
          },
          {
            "type": "string",
            "optional": false,
            "field": "first_name"
          },
          {
            "type": "string",
            "optional": false,
            "field": "last_name"
          },
          {
            "type": "string",
            "optional": false,
            "field": "email"
          }
        ],
        "optional": true,
        "name": "dbserver_mysql.inventory.customers.Value",
        "field": "after"
      },
      {
        "type": "struct",
        "fields": [
          {
            "type": "string",
            "optional": false,
            "field": "version"
          },
          {
            "type": "string",
            "optional": false,
            "field": "connector"
          },
          {
            "type": "string",
            "optional": false,
            "field": "name"
          },
          {
            "type": "int64",
            "optional": false,
            "field": "ts_ms"
          },
          {
            "type": "string",
            "optional": true,
            "name": "io.debezium.data.Enum",
            "version": 1,
            "parameters": {
              "allowed": "true,last,false"
            },
            "default": "false",
            "field": "snapshot"
          },
          {
            "type": "string",
            "optional": false,
            "field": "db"
          },
          {
            "type": "string",
            "optional": true,
            "field": "table"
          },
          {
            "type": "int64",
            "optional": false,
            "field": "server_id"
          },
          {
            "type": "string",
            "optional": true,
            "field": "gtid"
          },
          {
            "type": "string",
            "optional": false,
            "field": "file"
          },
          {
            "type": "int64",
            "optional": false,
            "field": "pos"
          },
          {
            "type": "int32",
            "optional": false,
            "field": "row"
          },
          {
            "type": "int64",
            "optional": true,
            "field": "thread"
          },
          {
            "type": "string",
            "optional": true,
            "field": "query"
          }
        ],
        "optional": false,
        "name": "io.debezium.connector.mysql.Source",
        "field": "source"
      },
      {
        "type": "string",
        "optional": false,
        "field": "op"
      },
      {
        "type": "int64",
        "optional": true,
        "field": "ts_ms"
      },
      {
        "type": "struct",
        "fields": [
          {
            "type": "string",
            "optional": false,
            "field": "id"
          },
          {
            "type": "int64",
            "optional": false,
            "field": "total_order"
          },
          {
            "type": "int64",
            "optional": false,
            "field": "data_collection_order"
          }
        ],
        "optional": true,
        "field": "transaction"
      }
    ],
    "optional": false,
    "name": "dbserver_mysql.inventory.customers.Envelope"
  },
  "payload": {
    "before": null,
    "after": {
      "id": 1003,
      "first_name": "Edward",
      "last_name": "Walker",
      "email": "ed@walker.com"
    },
    "source": {
      "version": "1.1.2.Final-redhat-00001",
      "connector": "mysql",
      "name": "dbserver-mysql",
      "ts_ms": 0,
      "snapshot": "true",
      "db": "inventory",
      "table": "customers",
      "server_id": 0,
      "gtid": null,
      "file": "mysql-bin.000003",
      "pos": 154,
      "row": 0,
      "thread": null,
      "query": null
    },
    "op": "c",
    "ts_ms": 1594158476924,
    "transaction": null
  }
}
----

. Compare the _key_ and _value_ schemas of the event to the state of the `inventory` database by comparing them 
to the customer table that the SQL query returned in the previous task: 
+
----
+------+------------+-----------+-----------------------+
| id   | first_name | last_name | email                 |
+------+------------+-----------+-----------------------+
| 1001 | Sally      | Thomas    | sally.thomas@acme.com |
| 1002 | George     | Bailey    | gbailey@foobar.com    |
| 1003 | Edward     | Walker    | ed@walker.com         |
| 1004 | Anne       | Kretchmar | annek@noanswer.org    |
+------+------------+-----------+-----------------------+
----

[type=verification]
====
Did it work?
====

[type=verificationFail]
{standard-fail-text}
// <-- END OF SOLUTION PATTERN TASKS -->

// <-- START OF SOLUTION PATTERN TASKS -->
[time=5]
[id='viewing-update-event']
== Updating the database and viewing the UPDATE event

Now that you have seen how the Debezium MySQL connector captured the CREATE events in the `inventory` database, you will now change one of the records and see how the connector captures it.

=== Updating a customer

. In the terminal that is running the MySQL command line client, run the following statement:
+
[source,bash,subs="attributes+"]
----
UPDATE customers SET first_name='Anne Marie' WHERE id=1004;
----

. View the updated `customers` table::
+
[source,bash,subs="attributes+"]
----
SELECT * FROM customers;
----
+
You should get the updated version:
+
----
+------+------------+-----------+-----------------------+
| id   | first_name | last_name | email                 |
+------+------------+-----------+-----------------------+
| 1001 | Sally      | Thomas    | sally.thomas@acme.com |
| 1002 | George     | Bailey    | gbailey@foobar.com    |
| 1003 | Edward     | Walker    | ed@walker.com         |
| 1004 | Anne Marie | Kretchmar | annek@noanswer.org    |
+------+------------+-----------+-----------------------+

4 rows in set
Time: 0.011s
----

=== Reviewing the Kafka record

. Switch back to the terminal running `kafkacat` and re-run the last command (press Ctrl + C to stop the current one):
+
[source,bash,subs="attributes+"]
----
kafkacat -b demo-kafka-bootstrap:9092 -t dbserver-mysql.inventory.customers -e | jq .
----
+
By changing a record in the `customers` table, the Debezium MySQL connector generated a new event. You should see two new JSON documents: one for the event’s _key_, and one for the new event’s _value_.
+
Here is that new event’s _value_. There are no changes in the `schema` section, so only the `payload` section is shown (formatted for readability):
+
----
...
  "payload": {
    "before": {
      "id": 1004,
      "first_name": "Anne",
      "last_name": "Kretchmar",
      "email": "annek@noanswer.org"
    },
    "after": {
      "id": 1004,
      "first_name": "Anne Marie",
      "last_name": "Kretchmar",
      "email": "annek@noanswer.org"
    },
    "source": {
      "version": "1.1.2.Final-redhat-00001",
      "connector": "mysql",
      "name": "dbserver-mysql",
      "ts_ms": 1594235095000,
      "snapshot": "false",
      "db": "inventory",
      "table": "customers",
      "server_id": 223344,
      "gtid": null,
      "file": "mysql-bin.000003",
      "pos": 364,
      "row": 0,
      "thread": 19,
      "query": null
    },
    "op": "u",
    "ts_ms": 1594235095071,
    "transaction": null
  }
}
----
+
[NOTE]
====
The `before` field now has the state of the row with the values _before_ the database commit.
====

By viewing the `payload` section, you can learn several important things about the _update_ event:

- By comparing the `before` and `after` structures, you can determine what actually changed in the affected row because of the commit.
- By reviewing the `source` structure, you can find information about MySQL’s record of the change (providing traceability).
- By comparing the `payload` section of an event to other events in the same topic (or a different topic), you can determine whether the event occurred before, after, or as part of the same MySQL commit as another event.

[type=verification]
====
Did it work?
====

[type=verificationFail]
{standard-fail-text}
// <-- END OF SOLUTION PATTERN TASKS -->

// <-- START OF SOLUTION PATTERN TASKS -->
[time=5]
[id='viewing-delete-event']
== Deleting a record in the database and viewing the _delete_ event

Now that you have seen how the Debezium MySQL connector captured the _create_ and _update_ events in the `inventory` database, you will now delete one of the records and see how the connector captures it.

=== Deleting a customer and addresses

. In the terminal that is running the MySQL command line client, run the following statements:
+
[source,bash,subs="attributes+"]
----
DELETE FROM addresses WHERE customer_id=1004;
DELETE FROM customers WHERE id=1004;
----
+
[NOTE]
====
You will need to type `y` to proceed for each statement.
====
+
By deleting a row in the `customers` table, the Debezium MySQL connector generated two new events.

=== Review the Kafka record

. Switch back to the terminal running `kafkacat` and the following command:
+
[source,bash,subs="attributes+"]
----
kafkacat -b demo-kafka-bootstrap:9092 -t dbserver-mysql.inventory.customers -K \n -e
----

. Review the _value_ for the first new event.
+
Here are the details of the _value_ for the first new event (formatted for readability):
+
----
{
...
  "payload": {
    "before": {
      "id": 1004,
      "first_name": "Anne Marie",
      "last_name": "Kretchmar",
      "email": "annek@noanswer.org"
    },
    "after": null,
    "source": {
      "version": "1.1.2.Final-redhat-00001",
      "connector": "mysql",
      "name": "dbserver-mysql",
      "ts_ms": 1594236194000,
      "snapshot": "false",
      "db": "inventory",
      "table": "customers",
      "server_id": 223344,
      "gtid": null,
      "file": "mysql-bin.000003",
      "pos": 1066,
      "row": 0,
      "thread": 19,
      "query": null
    },
    "op": "d",
    "ts_ms": 1594236194613,
    "transaction": null
  }
}
----
+
[NOTE]
====
The `before` field now has the state of the row that was deleted with the database commit.

This event provides a consumer with the information that it needs to process the removal of the row. The old values are also provided, because some consumers might require them to properly handle the removal.
====

. Review the _key_ and _value_ for the second new event.
+
Here is the _key_ for the second new event (formatted for readability):
+
----
{
  "schema": {
    "type": "struct",
    "fields": [
      {
        "type": "int32",
        "optional": false,
        "field": "id"
      }
    ],
    "optional": false,
    "name": "dbserver_mysql.inventory.customers.Key"
  },
  "payload": {
    "id": 1004
  }
}
----
+
[NOTE]
Did you noticed that this time there is no message payload?

If Kafka is set up to be _log compacted_, it will remove older messages from the topic if there is at least one message later in the topic with same key. This last event is called a _tombstone_ event, because it has a key and an empty value. This means that Kafka will remove all prior messages with the same key. Even though the prior messages will be removed, the tombstone event means that consumers can still read the topic from the beginning and not miss any events.

[type=verification]
====
Did it work?
====

[type=verificationFail]
{standard-fail-text}
// <-- END OF SOLUTION PATTERN TASKS -->


// <-- START OF SOLUTION PATTERN TASKS -->
[time=5]
[id='summary']
== Summary

After completing the tutorial, consider the following next steps:

- Explore the tutorial further.
+
Use the MySQL command line client to add, modify, and remove rows in the database tables, and see the effect on the topics. Keep in mind that you cannot remove a row that is referenced by a foreign key.

- Plan a Debezium deployment.
+
====
You can install Debezium in OpenShift or on Red Hat Enterprise Linux. For more information, see the following:

- link:https://access.redhat.com/documentation/en-us/red_hat_integration/2020-Q2/html-single/installing_change_data_capture_on_openshift/[Installing Debezium on OpenShift, window="_blank"]
- link:https://access.redhat.com/documentation/en-us/red_hat_integration/2020-Q2/html-single/installing_change_data_capture_on_rhel/[Installing Debezium on RHEL, window="_blank"]
====

// <-- END OF SOLUTION PATTERN TASKS -->
